{'epochs': 60, 'lr': 0.02, 'frz': 15, 'pre': (682, 1024), 're': 256, 'bs': 64, 'smooth': True, 'arch': 'resnet50', 'dump': False, 'log': False, 'save': False, 'mixup': 0.0, 'tta': True, 'fp16': True, 'eval_dir': Path('resnet50-pseudo'), 'val_fold': None, 'pseudo': Path('resnet50/pseudo_labels.csv')}

Training on fold 0
# train exs: 1473, val exs: 365
█epoch     train_loss  valid_loss  accuracy  roc_auc_score  time    
██0         1.685069    1.328880    0.838356  0.939037       00:27     
██1         1.280294    1.408079    0.641096  0.865735       00:23     
██2         1.012363    0.817026    0.841096  0.931350       00:23     
██3         0.865067    0.719466    0.849315  0.942077       00:23     
██4         0.797980    0.767101    0.860274  0.955114       00:23     
██5         0.724835    0.514597    0.923288  0.976870       00:23     
██6         0.674646    0.625593    0.942466  0.965549       00:23     
██7         0.646313    0.679011    0.841096  0.953710       00:23     
██8         0.608399    0.555493    0.945205  0.969897       00:23     
██9         0.573896    0.473568    0.969863  0.984426       00:23     
██10        0.547242    0.437788    0.969863  0.992327       00:23     
██11        0.523063    0.445685    0.964384  0.983785       00:23     
██12        0.504625    0.429970    0.972603  0.990223       00:23     
██13        0.485656    0.429643    0.967123  0.990476       00:23     
██14        0.472810    0.426887    0.967123  0.990373       00:23     
█epoch     train_loss  valid_loss  accuracy  roc_auc_score  time    
██0         0.488157    0.454617    0.958904  0.979097       00:26     
██1         0.480678    0.458482    0.958904  0.983648       00:25     
██2         0.488409    0.477683    0.950685  0.970375       00:26     
██3         0.487639    0.463011    0.942466  0.982989       00:26     
██4         0.487445    0.534311    0.923288  0.975271       00:25     
██5         0.507455    0.560759    0.928767  0.988441       00:26     
██6         0.511282    0.558674    0.928767  0.933715       00:26     
██7         0.519586    0.603317    0.879452  0.945949       00:26     
██8         0.524152    0.514837    0.934247  0.968825       00:26     
██9         0.534444    0.747494    0.827397  0.944492       00:26     
██10        0.524190    0.542852    0.928767  0.971087       00:25     
██11        0.522880    0.472912    0.953425  0.985608       00:26     
██12        0.518981    0.513605    0.928767  0.981992       00:26     
██13        0.530853    0.497269    0.939726  0.977366       00:26     
██14        0.541436    0.579417    0.931507  0.971855       00:26     
██15        0.537158    0.498934    0.950685  0.985065       00:26     
██16        0.523901    0.500690    0.945205  0.973278       00:26     
██17        0.507569    0.468414    0.950685  0.978801       00:26     
██18        0.501669    0.517888    0.936986  0.976045       00:26     
██19        0.499893    0.516568    0.928767  0.990109       00:26     
██20        0.497266    0.492385    0.934247  0.984549       00:26     
██21        0.499960    0.592726    0.904110  0.955070       00:26     
██22        0.495891    0.458503    0.953425  0.987669       00:26     
██23        0.487750    0.478174    0.953425  0.984321       00:26     
██24        0.482801    0.448620    0.969863  0.988447       00:26     
██25        0.481729    0.527698    0.934247  0.965563       00:26     
██26        0.477183    0.478551    0.942466  0.978799       00:26     
██27        0.472143    0.525717    0.926027  0.971814       00:26     
██28        0.463958    0.462997    0.950685  0.986325       00:26     
██29        0.471533    0.454058    0.947945  0.993593       00:26     
██30        0.462298    0.452024    0.950685  0.991357       00:26     
██31        0.460156    0.460062    0.953425  0.985281       00:26     
██32        0.456592    0.470078    0.956164  0.980864       00:26     
██33        0.454702    0.452488    0.947945  0.984589       00:26     
██34        0.452794    0.443874    0.956164  0.994524       00:26     
██35        0.451785    0.473919    0.939726  0.984186       00:27     
██36        0.448131    0.438989    0.958904  0.994468       00:26     
██37        0.444504    0.457078    0.953425  0.989669       00:26     
██38        0.439884    0.471684    0.942466  0.983252       00:27     
██39        0.442219    0.458021    0.956164  0.985328       00:26     
██40        0.438273    0.490919    0.939726  0.990966       00:27     
██41        0.442679    0.457047    0.956164  0.990169       00:27     
██42        0.439375    0.438528    0.958904  0.994589       00:27     
██43        0.427428    0.437824    0.964384  0.994139       00:26     
██44        0.430163    0.438292    0.961644  0.993630       00:27     
██45        0.428509    0.446098    0.967123  0.986908       00:27     
██46        0.428223    0.430781    0.967123  0.993136       00:27     
██47        0.424631    0.425475    0.969863  0.994242       00:27     
██48        0.415747    0.427450    0.969863  0.993237       00:27     
██49        0.413347    0.424038    0.967123  0.995131       00:27     
██50        0.415131    0.437181    0.964384  0.989448       00:27     
██51        0.410597    0.430060    0.969863  0.992473       00:27     
██52        0.410515    0.424843    0.967123  0.993852       00:27     
██53        0.409673    0.424313    0.967123  0.994564       00:27     
██54        0.407622    0.427600    0.967123  0.994220       00:27     
██55        0.404667    0.427160    0.964384  0.992871       00:27     
██56        0.401838    0.424472    0.967123  0.994514       00:27     
██57        0.400913    0.426377    0.964384  0.994202       00:27     
██58        0.401749    0.426265    0.964384  0.994122       00:27     
██59        0.404521    0.424821    0.967123  0.994543       00:27     
█epoch     train_loss  valid_loss  accuracy  roc_auc_score  time    
██████Evaluating
█epoch     train_loss  valid_loss  accuracy  roc_auc_score  time    
██████
Training on fold 1
# train exs: 1474, val exs: 364
█epoch     train_loss  valid_loss  accuracy  roc_auc_score  time    
██0         1.816836    2.075794    0.714286  0.892801       00:25     
██1         1.292027    0.952990    0.854396  0.937843       00:25     
██2         1.034012    0.957941    0.829670  0.924913       00:24     
██3         0.934593    0.657010    0.876374  0.957447       00:25     
██4         0.821910    0.585263    0.914835  0.968415       00:25     
██5         0.744371    0.668582    0.920330  0.943952       00:25     
██6         0.678106    0.532936    0.947802  0.983743       00:25     
██7         0.636174    0.502294    0.934066  0.975728       00:25     
██8         0.592828    0.542071    0.923077  0.986389       00:24     
██9         0.560032    0.484496    0.947802  0.969911       00:24     
██10        0.538123    0.471346    0.939560  0.983475       00:25     
██11        0.519958    0.455650    0.947802  0.991027       00:24     
██12        0.498233    0.454750    0.950549  0.990867       00:24     
██13        0.490849    0.452379    0.947802  0.991204       00:25     
██14        0.474045    0.451333    0.947802  0.991173       00:24     
█epoch     train_loss  valid_loss  accuracy  roc_auc_score  time    
██0         0.496990    0.504192    0.931319  0.972217       00:27     
██1         0.488919    0.477492    0.950549  0.982922       00:27     
██2         0.480369    0.473904    0.942308  0.986322       00:27     
██3         0.482038    0.734444    0.821429  0.934980       00:27     
██4         0.497315    0.572312    0.912088  0.976010       00:27     
██5         0.497827    0.551335    0.901099  0.974156       00:27     
██6         0.509952    0.534626    0.931319  0.984467       00:27     
██7         0.511582    0.533153    0.931319  0.938674       00:27     
██8         0.515875    0.632101    0.870879  0.960386       00:27     
██9         0.527122    0.694010    0.821429  0.937822       00:27     
██10        0.531079    0.547386    0.936813  0.977456       00:27     
██11        0.530683    0.668196    0.851648  0.948237       00:27     
██12        0.525071    0.558174    0.914835  0.960644       00:27     
██13        0.521010    0.522594    0.931319  0.971126       00:27     
██14        0.521680    0.465832    0.945055  0.982599       00:27     
██15        0.522434    0.511728    0.928571  0.974768       00:27     
██16        0.515802    0.494954    0.936813  0.971282       00:27     
██17        0.502427    0.518810    0.939560  0.950769       00:27     
██18        0.501696    0.498445    0.936813  0.963587       00:27     
██19        0.500268    0.504366    0.942308  0.976036       00:27     
██20        0.504421    0.546012    0.914835  0.965336       00:27     
██21        0.494548    0.514647    0.931319  0.974847       00:27     
██22        0.492335    0.493153    0.942308  0.984358       00:27     
██23        0.494944    0.552204    0.934066  0.956604       00:27     
██24        0.479389    0.461247    0.953297  0.989173       00:27     
██25        0.476784    0.456558    0.961538  0.987808       00:27     
██26        0.472331    0.952267    0.733516  0.947612       00:27     
██27        0.475136    0.491847    0.945055  0.980530       00:27     
██28        0.466363    0.493147    0.928571  0.973054       00:27     
██29        0.461342    0.477938    0.945055  0.973529       00:27     
██30        0.461313    0.482173    0.947802  0.976964       00:27     
██31        0.461816    0.461699    0.950549  0.985989       00:27     
██32        0.452751    0.650979    0.876374  0.962012       00:27     
██33        0.445865    0.477729    0.942308  0.978344       00:27     
██34        0.447372    0.448214    0.961538  0.990866       00:27     
██35        0.450162    0.459548    0.953297  0.990912       00:27     
██36        0.443614    0.450144    0.953297  0.989587       00:27     
██37        0.441363    0.431710    0.958791  0.995220       00:27     
██38        0.440465    0.452170    0.950549  0.991406       00:27     
██39        0.436849    0.449021    0.953297  0.985546       00:27     
██40        0.432251    0.437721    0.964286  0.993297       00:27     
██41        0.433643    0.452270    0.958791  0.990090       00:27     
██42        0.433335    0.441049    0.961538  0.992455       00:27     
██43        0.430207    0.453167    0.945055  0.993378       00:27     
██44        0.426567    0.452419    0.956044  0.988458       00:27     
██45        0.419718    0.436893    0.967033  0.990145       00:27     
██46        0.419930    0.446391    0.964286  0.988221       00:27     
██47        0.415985    0.442203    0.956044  0.989259       00:27     
██48        0.413414    0.433707    0.964286  0.991460       00:27     
██49        0.407797    0.437037    0.964286  0.990628       00:27     
██50        0.405409    0.432384    0.961538  0.991687       00:27     
██51        0.408593    0.434832    0.958791  0.991907       00:27     
██52        0.405178    0.433849    0.969780  0.991317       00:27     
██53        0.406138    0.434991    0.972527  0.991415       00:27     
██54        0.403640    0.432592    0.969780  0.992465       00:27     
██55        0.400717    0.433160    0.967033  0.992862       00:26     
██56        0.402050    0.434763    0.972527  0.991951       00:26     
██57        0.407792    0.436725    0.969780  0.991520       00:26     
██58        0.405117    0.434930    0.967033  0.991952       00:26     
██59        0.404976    0.436517    0.967033  0.992020       00:27     
█epoch     train_loss  valid_loss  accuracy  roc_auc_score  time    
██████Evaluating
█epoch     train_loss  valid_loss  accuracy  roc_auc_score  time    
██████
Training on fold 2
# train exs: 1474, val exs: 364
█epoch     train_loss  valid_loss  accuracy  roc_auc_score  time    
██0         1.762164    1.332332    0.840659  0.920399       00:25     
██1         1.316103    0.841844    0.868132  0.900624       00:24     
██2         1.032560    0.781591    0.868132  0.942006       00:25     
██3         0.922080    1.122672    0.615385  0.805383       00:24     
██4         0.868371    0.660698    0.923077  0.946009       00:24     
██5         0.763101    0.583265    0.901099  0.956718       00:25     
██6         0.696011    0.565616    0.906593  0.959699       00:24     
██7         0.640383    0.544070    0.928571  0.970341       00:25     
██8         0.600557    0.518469    0.931319  0.963044       00:25     
██9         0.562899    0.515920    0.920330  0.971165       00:25     
██10        0.538561    0.474626    0.945055  0.985096       00:25     
██11        0.513992    0.458002    0.961538  0.983999       00:24     
██12        0.492868    0.458749    0.939560  0.985128       00:25     
██13        0.475361    0.454241    0.947802  0.985289       00:25     
██14        0.463361    0.456018    0.947802  0.985571       00:25     
█epoch     train_loss  valid_loss  accuracy  roc_auc_score  time    
██0         0.463976    0.494830    0.958791  0.968385       00:27     
██1         0.465912    0.462640    0.947802  0.979628       00:27     
██2         0.467638    0.492661    0.945055  0.972964       00:27     
██3         0.475083    0.497077    0.923077  0.972231       00:27     
██4         0.474279    0.623022    0.870879  0.933091       00:27     
██5         0.492765    0.571923    0.923077  0.942548       00:27     
██6         0.510087    0.557916    0.914835  0.971141       00:27     
██7         0.520276    0.699090    0.923077  0.912728       00:27     
██8         0.532149    0.599307    0.892857  0.978038       00:27     
██9         0.530619    0.578987    0.903846  0.967608       00:27     
██10        0.533403    0.582974    0.879121  0.960079       00:27     
██11        0.526478    0.496351    0.945055  0.956656       00:27     
██12        0.529254    0.541900    0.931319  0.948227       00:27     
██13        0.540750    0.554980    0.942308  0.952299       00:27     
██14        0.524736    0.526262    0.928571  0.977925       00:27     
██15        0.510931    0.506675    0.931319  0.966284       00:27     
██16        0.515216    0.479007    0.942308  0.981926       00:26     
██17        0.516206    0.564351    0.895604  0.976422       00:27     
██18        0.522029    0.555288    0.942308  0.942723       00:27     
██19        0.522313    0.500162    0.939560  0.974443       00:27     
██20        0.511566    0.598063    0.859890  0.954052       00:27     
██21        0.500527    0.527535    0.923077  0.953880       00:27     
██22        0.492691    0.460672    0.953297  0.980898       00:26     
██23        0.485545    0.641655    0.879121  0.960146       00:26     
██24        0.481709    0.635895    0.835165  0.946374       00:26     
██25        0.480061    0.471563    0.945055  0.982154       00:26     
██26        0.474135    0.501631    0.923077  0.971462       00:26     
██27        0.469675    0.462644    0.956044  0.976478       00:26     
██28        0.470320    0.474313    0.950549  0.968673       00:26     
██29        0.463499    0.453273    0.958791  0.976325       00:26     
██30        0.455000    0.458903    0.950549  0.979891       00:26     
██31        0.455755    0.541367    0.934066  0.959254       00:26     
██32        0.460568    0.507205    0.914835  0.975602       00:26     
██33        0.458208    0.473236    0.942308  0.980824       00:26     
██34        0.449296    0.461155    0.945055  0.977146       00:26     
██35        0.444958    0.445997    0.953297  0.977674       00:26     
██36        0.437032    0.451102    0.953297  0.979033       00:26     
██37        0.437859    0.454938    0.953297  0.972913       00:26     
██38        0.433520    0.488530    0.936813  0.974515       00:26     
██39        0.431210    0.458589    0.950549  0.976208       00:26     
██40        0.427462    0.445621    0.953297  0.985225       00:26     
██41        0.434198    0.446737    0.958791  0.974361       00:26     
██42        0.432083    0.441852    0.964286  0.976594       00:26     
██43        0.424325    0.445271    0.961538  0.980588       00:26     
██44        0.418008    0.441009    0.961538  0.977957       00:26     
██45        0.415038    0.432848    0.964286  0.980267       00:26     
██46        0.413351    0.432545    0.967033  0.983588       00:26     
██47        0.410533    0.437145    0.964286  0.981327       00:26     
██48        0.410503    0.435006    0.964286  0.982367       00:26     
██49        0.408673    0.435761    0.961538  0.983669       00:26     
██50        0.405431    0.437339    0.964286  0.981851       00:26     
██51        0.403606    0.435964    0.964286  0.982092       00:26     
██52        0.400822    0.433067    0.964286  0.981581       00:26     
██53        0.403799    0.430148    0.967033  0.980163       00:26     
██54        0.400905    0.428840    0.967033  0.980018       00:26     
██55        0.398461    0.428874    0.964286  0.981006       00:26     
██56        0.399475    0.429254    0.961538  0.981297       00:26     
██57        0.400506    0.427819    0.967033  0.980038       00:26     
██58        0.403632    0.429501    0.964286  0.980580       00:26     
██59        0.406525    0.429690    0.961538  0.980318       00:26     
█epoch     train_loss  valid_loss  accuracy  roc_auc_score  time    
██████Evaluating
█epoch     train_loss  valid_loss  accuracy  roc_auc_score  time    
██████
Training on fold 3
# train exs: 1474, val exs: 364
█epoch     train_loss  valid_loss  accuracy  roc_auc_score  time    
██0         1.856243    1.278268    0.815934  0.923021       00:23     
██1         1.327845    0.781962    0.785714  0.909484       00:23     
██2         1.021166    0.844754    0.912088  0.924394       00:23     
██3         0.911050    0.863500    0.898352  0.940015       00:23     
██4         0.869257    0.752322    0.879121  0.920015       00:23     
██5         0.785517    0.674747    0.884615  0.949164       00:23     
██6         0.714462    0.602927    0.901099  0.957118       00:23     
██7         0.645998    0.502601    0.942308  0.970552       00:23     
██8         0.593048    0.484254    0.942308  0.976601       00:23     
██9         0.561392    0.485044    0.947802  0.975762       00:23     
██10        0.540724    0.456960    0.958791  0.974194       00:23     
██11        0.518040    0.465204    0.950549  0.976326       00:23     
██12        0.501802    0.456580    0.958791  0.977103       00:24     
██13        0.483126    0.449160    0.958791  0.978774       00:23     
██14        0.470616    0.448032    0.956044  0.979002       00:24     
█epoch     train_loss  valid_loss  accuracy  roc_auc_score  time    
██0         0.490040    0.488039    0.934066  0.971586       00:26     
██1         0.476658    0.466380    0.947802  0.976032       00:26     
██2         0.467590    0.460650    0.964286  0.969815       00:26     
██3         0.476216    0.626577    0.873626  0.960789       00:26     
██4         0.494508    0.526674    0.901099  0.967084       00:26     
██5         0.497633    0.502650    0.931319  0.966508       00:26     
██6         0.496200    0.542828    0.931319  0.964106       00:26     
██7         0.501114    0.510602    0.928571  0.961225       00:26     
██8         0.504284    0.558515    0.903846  0.952407       00:26     
██9         0.509369    0.531648    0.936813  0.947752       00:26     
██10        0.525506    0.577310    0.931319  0.958235       00:26     
██11        0.521834    0.520785    0.931319  0.950529       00:26     
██12        0.527443    0.555425    0.939560  0.965339       00:26     
██13        0.526966    0.578015    0.917582  0.961561       00:26     
██14        0.513521    0.487907    0.947802  0.961531       00:26     
██15        0.514138    0.609870    0.906593  0.948915       00:26     
██16        0.511591    0.521327    0.936813  0.956337       00:26     
██17        0.501040    0.498380    0.923077  0.962850       00:26     
██18        0.498519    0.533922    0.936813  0.963137       00:26     
██19        0.513505    0.517490    0.931319  0.949404       00:26     
██20        0.503794    0.488985    0.928571  0.962378       00:26     
██21        0.501258    0.480321    0.945055  0.965267       00:26     
██22        0.498107    0.558972    0.923077  0.955164       00:26     
██23        0.487170    0.479701    0.947802  0.969638       00:26     
██24        0.483646    0.521758    0.936813  0.966836       00:26     
██25        0.481471    0.501722    0.931319  0.967149       00:26     
██26        0.476922    0.473252    0.958791  0.957656       00:26     
██27        0.472269    0.465409    0.945055  0.972686       00:26     
██28        0.471692    0.721273    0.837912  0.910678       00:26     
██29        0.467672    0.479938    0.950549  0.965000       00:26     
██30        0.465506    0.453007    0.950549  0.974380       00:26     
██31        0.459719    0.467885    0.945055  0.972146       00:26     
██32        0.450368    0.468966    0.947802  0.967126       00:26     
██33        0.446357    0.499267    0.936813  0.963892       00:26     
██34        0.443730    0.454003    0.956044  0.968367       00:26     
██35        0.445238    0.467145    0.950549  0.971231       00:26     
██36        0.444185    0.455565    0.950549  0.978290       00:26     
██37        0.447354    0.445557    0.950549  0.975207       00:26     
██38        0.446305    0.455893    0.950549  0.970166       00:26     
██39        0.438355    0.463049    0.950549  0.965619       00:26     
██40        0.438995    0.450869    0.956044  0.976006       00:26     
██41        0.434736    0.451769    0.953297  0.970172       00:26     
██42        0.428606    0.448437    0.958791  0.977572       00:26     
██43        0.422144    0.442581    0.958791  0.973482       00:26     
██44        0.423515    0.446007    0.953297  0.972556       00:26     
██45        0.417800    0.441530    0.956044  0.979633       00:26     
██46        0.412238    0.444872    0.958791  0.974018       00:26     
██47        0.409342    0.433901    0.967033  0.976784       00:26     
██48        0.405080    0.437627    0.964286  0.978153       00:26     
██49        0.403902    0.437714    0.964286  0.977356       00:26     
██50        0.403935    0.438841    0.964286  0.976869       00:26     
██51        0.408271    0.438302    0.964286  0.976519       00:26     
██52        0.405128    0.440485    0.964286  0.976078       00:26     
██53        0.403097    0.438498    0.964286  0.976560       00:26     
██54        0.403513    0.438636    0.961538  0.976712       00:26     
██55        0.402543    0.439254    0.961538  0.976995       00:26     
██56        0.405183    0.438503    0.961538  0.977211       00:26     
██57        0.400866    0.436653    0.961538  0.977460       00:26     
██58        0.401576    0.439553    0.953297  0.977514       00:26     
██59        0.405728    0.439686    0.953297  0.977659       00:26     
█epoch     train_loss  valid_loss  accuracy  roc_auc_score  time    
██████Evaluating
█epoch     train_loss  valid_loss  accuracy  roc_auc_score  time    
██████
Training on fold 4
# train exs: 1474, val exs: 364
█epoch     train_loss  valid_loss  accuracy  roc_auc_score  time    
██0         1.904609    1.274868    0.793956  0.905409       00:24     
██1         1.352844    1.130131    0.695055  0.858812       00:24     
██2         1.060894    0.722114    0.843407  0.945614       00:24     
██3         0.918977    0.861205    0.824176  0.924508       00:24     
██4         0.826144    0.660719    0.909341  0.938214       00:24     
██5         0.753589    0.561748    0.939560  0.958325       00:24     
██6         0.684440    0.488320    0.950549  0.977580       00:24     
██7         0.626562    0.498886    0.950549  0.973222       00:24     
██8         0.588060    0.473129    0.953297  0.970696       00:24     
██9         0.552520    0.474470    0.947802  0.976829       00:24     
██10        0.529562    0.476800    0.950549  0.972811       00:24     
██11        0.508260    0.452302    0.958791  0.983224       00:24     
██12        0.496342    0.460288    0.956044  0.977927       00:24     
██13        0.486768    0.457432    0.956044  0.979151       00:24     
██14        0.473305    0.455949    0.953297  0.979013       00:24     
█epoch     train_loss  valid_loss  accuracy  roc_auc_score  time    
██0         0.471007    0.449619    0.964286  0.974212       00:26     
██1         0.482623    0.478117    0.947802  0.976814       00:26     
██2         0.472171    0.497555    0.947802  0.970134       00:26     
██3         0.483839    0.529084    0.939560  0.943224       00:26     
██4         0.488012    0.509334    0.936813  0.950744       00:26     
██5         0.489244    0.496695    0.936813  0.972236       00:26     
██6         0.497696    0.593909    0.901099  0.926989       00:26     
██7         0.504289    0.693604    0.840659  0.953978       00:26     
██8         0.513713    0.690484    0.892857  0.943602       00:26     
██9         0.514044    0.569325    0.914835  0.945764       00:26     
██10        0.524627    0.515132    0.923077  0.959747       00:26     
██11        0.531760    0.470290    0.950549  0.975427       00:26     
██12        0.523903    0.670501    0.881868  0.917940       00:26     
██13        0.530664    0.611943    0.881868  0.955636       00:26     
██14        0.519653    0.523504    0.925824  0.971260       00:26     
██15        0.525823    0.524709    0.931319  0.958788       00:26     
██16        0.519097    0.630233    0.870879  0.957693       00:26     
██17        0.509757    0.476225    0.947802  0.970408       00:26     
██18        0.510829    0.457986    0.956044  0.975495       00:26     
██19        0.500526    0.447081    0.967033  0.987655       00:26     
██20        0.496803    0.477135    0.950549  0.975843       00:26     
██21        0.490783    0.454599    0.961538  0.973653       00:26     
██22        0.491552    0.464410    0.950549  0.974696       00:26     
██23        0.484442    0.433540    0.969780  0.985880       00:26     
██24        0.481252    0.473409    0.945055  0.975731       00:26     
██25        0.480966    0.443586    0.964286  0.972654       00:26     
██26        0.479753    0.451728    0.961538  0.976109       00:26     
██27        0.459830    0.438988    0.958791  0.981366       00:26     
██28        0.458769    0.467575    0.956044  0.969406       00:26     
██29        0.460055    0.443319    0.956044  0.989045       00:26     
██30        0.461575    0.441839    0.956044  0.982237       00:26     
██31        0.463414    0.508783    0.928571  0.971879       00:26     
██32        0.456303    0.434086    0.961538  0.983875       00:26     
██33        0.456314    0.452785    0.958791  0.981810       00:26     
██34        0.453640    0.470319    0.950549  0.976495       00:26     
██35        0.451765    0.444467    0.958791  0.973979       00:26     
██36        0.442160    0.448900    0.964286  0.974116       00:26     
██37        0.439804    0.444038    0.953297  0.977347       00:26     
██38        0.438116    0.452893    0.956044  0.969824       00:26     
██39        0.431851    0.445392    0.961538  0.975094       00:26     
██40        0.432000    0.444799    0.958791  0.977793       00:26     
██41        0.426537    0.444854    0.953297  0.975132       00:26     
██42        0.423765    0.436260    0.956044  0.980144       00:26     
██43        0.420254    0.431722    0.964286  0.979491       00:26     
██44        0.418235    0.431795    0.967033  0.980199       00:26     
██45        0.417565    0.437194    0.967033  0.978529       00:26     
██46        0.415411    0.425048    0.964286  0.984066       00:26     
██47        0.411429    0.439538    0.956044  0.983184       00:26     
██48        0.406371    0.438652    0.958791  0.984812       00:26     
██49        0.411635    0.434248    0.956044  0.981329       00:26     
██50        0.410176    0.431154    0.961538  0.978873       00:26     
██51        0.403470    0.429417    0.967033  0.981358       00:26     
██52        0.401966    0.432916    0.967033  0.982997       00:26     
██53        0.404303    0.436931    0.958791  0.981504       00:26     
██54        0.403461    0.432318    0.961538  0.983518       00:26     
██55        0.403083    0.431278    0.967033  0.982877       00:26     
██56        0.398953    0.431215    0.967033  0.982136       00:26     
██57        0.401131    0.431303    0.967033  0.982752       00:26     
██58        0.398078    0.431074    0.967033  0.982537       00:26     
██59        0.393885    0.430235    0.967033  0.981225       00:26     
█epoch     train_loss  valid_loss  accuracy  roc_auc_score  time    
██████Evaluating
█epoch     train_loss  valid_loss  accuracy  roc_auc_score  time    
██████Scores: [[0.90900087 0.969863   0.99542055]
 [0.91211414 0.96428573 0.99554807]
 [0.90535486 0.96428573 0.9815775 ]
 [0.91381383 0.95054942 0.97843616]
 [0.90590942 0.96703297 0.98618668]]

Mean: [0.90923862 0.96320337 0.98743379]
