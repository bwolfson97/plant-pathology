{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n",
    "\n",
    "> This module contains a script to train a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from plant_pathology.dataset import *\n",
    "from plant_pathology.evaluate import *\n",
    "\n",
    "from fastai.vision.all import *\n",
    "from fastcore.script import *\n",
    "from fastai.callback.wandb import *\n",
    "from wwf.vision.timm import *\n",
    "import timm\n",
    "import wandb\n",
    "from typing import *\n",
    "from sys import exit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Model on Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def timm_or_fastai_arch(arch: str) -> (Union[Any, str], Callable[..., Learner]):\n",
    "    try:  # Check if fastai arch\n",
    "        model = globals()[arch]\n",
    "        learner_func = cnn_learner\n",
    "    except KeyError:  # Must be timm arch\n",
    "        model = arch\n",
    "        learner_func = timm_learner\n",
    "    return model, learner_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def train(\n",
    "    epochs: int, lr: Union[float, str], frz: int=1, pre: int=800, re: int=256,\n",
    "    bs: int=256, fold: int=4, smooth: bool=False, \n",
    "    arch: str='resnet18', dump: bool=False, log: bool=False, mixup: float=0.,\n",
    "    fp16: bool=False, dls: DataLoaders=None, save: bool=False, pseudo: Path=None,\n",
    " ):\n",
    "    # Prep Data, Opt, Loss, Arch\n",
    "    if dls is None: dls = get_dls_all_in_1(presize=pre, resize=re, bs=bs, val_fold=fold, pseudo=pseudo)\n",
    "    if log: wandb.init(project=\"plant-pathology\")\n",
    "    if smooth: loss_func = LabelSmoothingCrossEntropyFlat()\n",
    "    else:      loss_func = CrossEntropyLossFlat()\n",
    "    m, learner_func = timm_or_fastai_arch(arch)\n",
    "    \n",
    "    # Add callbacks\n",
    "    cbs = [SaveModelCallback(\"roc_auc_score\", fname=f\"model_val_on_{fold}\")] if save or log else []\n",
    "    if log: cbs.append(WandbCallback())\n",
    "    if mixup: cbs.append(MixUp(mixup))\n",
    "        \n",
    "    # Build learner\n",
    "    print(f\"# train exs: {len(dls.train_ds)}, val exs: {len(dls.valid_ds)}\")\n",
    "    learn = learner_func(dls, m, loss_func=loss_func,\n",
    "                    metrics=[accuracy, RocAuc()], cbs=cbs)\n",
    "    if dump: print(learn.model); exit()\n",
    "    if lr==\"find\": learn.lr_find(); exit()\n",
    "    if fp16: learn.to_fp16()\n",
    "        \n",
    "    # Train\n",
    "    learn.freeze()\n",
    "    learn.fit_one_cycle(frz, lr)\n",
    "    learn.unfreeze()\n",
    "    learn.fit_one_cycle(epochs, slice(lr/100, lr/2))  # Explore other divs\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.994526</td>\n",
       "      <td>1.320189</td>\n",
       "      <td>0.552198</td>\n",
       "      <td>0.774509</td>\n",
       "      <td>00:47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = train(0, 0.001, bs=256, log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#4) [1.9945262670516968,1.3201892375946045,0.5521978139877319,0.7745089188919971]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.final_record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Using Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@call_parse\n",
    "def train_cv(\n",
    "    epochs:   Param(\"Number of unfrozen epochs\", int), \n",
    "    lr:       Param(\"Initial learning rate\", float), \n",
    "    frz:      Param(\"Number of frozen epochs\", int)=1, \n",
    "    pre:      Param(\"Presize\", int)=800, \n",
    "    re:       Param(\"Resize\", int)=256,\n",
    "    bs:       Param(\"Batch size\", int)=256,  \n",
    "    smooth:   Param(\"Label smoothing?\", store_true)=False, \n",
    "    arch:     Param(\"Architecture\", str)='resnet18', \n",
    "    dump:     Param(\"Print model\", store_true)=False, \n",
    "    log:      Param(\"Log w/ W&B\", store_true)=False,\n",
    "    save:     Param(\"Save model based on RocAuc\", store_true)=False,\n",
    "    mixup:    Param(\"Mixup (0.4 is good)\", float)=0.0,\n",
    "    tta:      Param(\"Test-time augmentation\", store_true)=False,\n",
    "    fp16:     Param(\"Use mixed-precision\", store_true)=False,\n",
    "    eval_dir: Param(\"Evaluate model, save results in dir\", Path)=None,\n",
    "    val_fold: Param(\"Only do 1 fold (4 is baseline, 9 for all data)\", int)=None,\n",
    "    pseudo:   Param(\"Path to pseudo labels to train on\", Path)=None,\n",
    "):\n",
    "    print(locals())\n",
    "    scores = []\n",
    "    for fold in range(5):\n",
    "        if val_fold is not None: fold = val_fold  # Not doing CV\n",
    "        print(f\"\\nTraining on fold {fold}\")\n",
    "        learn = train(epochs, lr, frz=frz, pre=pre, re=re, bs=bs, smooth=smooth, \n",
    "                      arch=arch, dump=dump, log=log, fold=fold, mixup=mixup,\n",
    "                      fp16=fp16, save=save, pseudo=pseudo)\n",
    "        \n",
    "        if tta and val_fold != -1:  # There IS a valid set\n",
    "            preds, lbls = learn.tta()\n",
    "            res = [f(preds, lbls) for f in [learn.loss_func, accuracy, RocAuc()]]\n",
    "        else: res = learn.final_record\n",
    "        scores.append(res)\n",
    "        \n",
    "        # Create submission file for this model\n",
    "        if eval_dir: print(\"Evaluating\"); evaluate(learn, Path(eval_dir)/f\"predictions_fold_{fold}.csv\", tta=tta)\n",
    "        \n",
    "        # Delete learner to avoid OOM\n",
    "        del learn\n",
    "        if val_fold is not None: break\n",
    "    scores = np.array(scores)\n",
    "    print(f\"Scores: {scores}\\n\")\n",
    "    if val_fold is None: print(f\"Mean: {scores.mean(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1.])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = np.ones((5, 4))\n",
    "scores.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 0, 'lr': 0.02, 'frz': 1, 'pre': 800, 're': 256, 'bs': 256, 'smooth': False, 'arch': 'resnet18', 'dump': False, 'log': False, 'mixup': 0.0, 'tta': False, 'fp16': False, 'eval_dir': None, 'val_fold': 4}\n",
      "\n",
      "Training on fold 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.411571</td>\n",
       "      <td>3.172661</td>\n",
       "      <td>0.725275</td>\n",
       "      <td>0.831642</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [[1.41157079 3.1726613  0.72527474 0.83164208]]\n",
      "\n",
      "Mean: [1.41157079 3.1726613  0.72527474 0.83164208]\n"
     ]
    }
   ],
   "source": [
    "train_cv(0, 2e-2, val_fold=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_dataset.ipynb.\n",
      "Converted 02_evaluate.ipynb.\n",
      "Converted 03_train.ipynb.\n",
      "Converted 04_generate_pseudo_labels.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
